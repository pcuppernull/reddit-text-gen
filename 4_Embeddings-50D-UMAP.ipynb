{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FINAL4d_Embeddings-quarterly-all_subreddits-50d-with-umap.ipynb","provenance":[{"file_id":"14fMTqA6ht50Sm8_V5hesIOKE5xScrEk0","timestamp":1623184327670},{"file_id":"1Eb4El-WLNUQLtg25Umcz_RqGM4PhywHo","timestamp":1623115475715}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOQTL6vOPMGta6++fYGKnoP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LaIbcuVd45v-"},"source":["This notebook takes the generated text, cleans it as necessary, creates the embeddings, and performs the dimension reduction."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8b9MhmIn5b2M","executionInfo":{"status":"ok","timestamp":1623187354319,"user_tz":420,"elapsed":192,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"64a84ac0-0225-4e57-b5e4-c08d86153334"},"source":["import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C-019530dq4x"},"source":["#!pip install git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okfrSLquxygw"},"source":["#!pip install -U yellowbrick"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"soP4EgFog8Gf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623187368456,"user_tz":420,"elapsed":3085,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"4c32ca7a-ce2b-4f8c-b5ab-184736335cd8"},"source":["!pip install umap-learn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.5.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.0.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VQrlaNqELNJu"},"source":["#import lucem_illud\n","import umap"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYjEaNnxLPjp"},"source":["import gensim\n","import pandas\n","import sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2XtpbhspFwP"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Oi9w4qqLPge"},"source":["import spacy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KouBZImhLPa7"},"source":["nlp = spacy.load(\"en\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5eS8yrJe5ZYG"},"source":["### Import Data and Clean"]},{"cell_type":"code","metadata":{"id":"-9WeaDNn41y9"},"source":["data_d = pd.read_csv(\"/content/drive/My Drive/Final Project/Data/text-generation-results/quarterly-democrats.csv\")\n","data_s = pd.read_csv(\"/content/drive/My Drive/Final Project/Data/text-generation-results/quarterly-socialism.csv\")\n","data_c17 = pd.read_csv(\"/content/drive/My Drive/Final Project/Data/text-generation-results/2017-conservative.csv\")\n","data_c18 = pd.read_csv(\"/content/drive/My Drive/Final Project/Data/text-generation-results/2018-conservative.csv\")\n","data_c19 = pd.read_csv(\"/content/drive/My Drive/Final Project/Data/text-generation-results/2019-conservative.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NAmRUn6vTcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623187379220,"user_tz":420,"elapsed":1035,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"7b3e25d4-748b-4858-b703-5b8fce162317"},"source":["#Socialism\n","for i in range(len(data_s)):\n","    seq_len = len(data_s.Prompt[i].split(\" \"))\n","    data_s.Result[i] = data_s.Result[i].replace(\"\\n\\n\", \" \\n\\n \")\n","    data_s.Result[i] = \" \".join(data_s.Result[i].split(\" \")[seq_len:])\n","\n","#Democrats\n","for i in range(len(data_d)):\n","    seq_len = len(data_d.Prompt[i].split(\" \"))\n","    data_d.Result[i] = data_d.Result[i].replace(\"\\n\\n\", \" \\n\\n \")\n","    data_d.Result[i] = \" \".join(data_d.Result[i].split(\" \")[seq_len:])\n","\n","#Conservative 2017\n","for i in range(len(data_c17)):\n","    seq_len = len(data_c17.Prompt[i].split(\" \"))\n","    data_c17.Result[i] = data_c17.Result[i].replace(\"\\n\\n\", \" \\n\\n \")\n","    data_c17.Result[i] = \" \".join(data_c17.Result[i].split(\" \")[seq_len:])\n","\n","#Conservative 2018\n","for i in range(len(data_c18)):\n","    seq_len = len(data_c18.Prompt[i].split(\" \"))\n","    data_c18.Result[i] = data_c18.Result[i].replace(\"\\n\\n\", \" \\n\\n \")\n","    data_c18.Result[i] = \" \".join(data_c18.Result[i].split(\" \")[seq_len:])\n","\n","#Conservative 2019\n","for i in range(len(data_c19)):\n","    seq_len = len(data_c19.Prompt[i].split(\" \"))\n","    data_c19.Result[i] = data_c19.Result[i].replace(\"\\n\\n\", \" \\n\\n \")\n","    data_c19.Result[i] = \" \".join(data_c19.Result[i].split(\" \")[seq_len:])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YcyGdasm2jKO"},"source":["# Add label column\n","data_s[\"label\"] = \"socialism\"\n","data_d[\"label\"] = \"democrats\"\n","data_c17[\"label\"] = \"conservative\"\n","data_c18[\"label\"] = \"conservative\"\n","data_c19[\"label\"] = \"conservative\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxUubA-c05Es"},"source":["# Only keep q1 and q2 for 2019 conservative\n","data_c19 = data_c19.iloc[0:540, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZS2ansUm3Ip7"},"source":["#for loop below\n","dfs = [\"data_c17\", \"data_c18\", \"data_c19\", \"data_d\", \"data_s\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnPjWY_s5Qsz"},"source":["#create quarter column for conservative data\n","data_c17['Quarter'] = 0\n","for i in range(len(data_c17)):\n","    if data_c17.Month[i] >= 1 and data_c17.Month[i] <= 3:\n","        data_c17.Quarter[i] = 1\n","    elif data_c17.Month[i] > 3 and data_c17.Month[i] <= 6:\n","        data_c17.Quarter[i] = 2\n","    elif data_c17.Month[i] > 6 and data_c17.Month[i] <= 9:\n","        data_c17.Quarter[i] = 3\n","    else:\n","        data_c17.Quarter[i] = 4\n","del data_c17['Month']\n","\n","data_c18['Quarter'] = 0\n","for i in range(len(data_c18)):\n","    if data_c18.Month[i] >= 1 and data_c18.Month[i] <= 3:\n","        data_c18.Quarter[i] = 1\n","    elif data_c18.Month[i] > 3 and data_c18.Month[i] <= 6:\n","        data_c18.Quarter[i] = 2\n","    elif data_c18.Month[i] > 6 and data_c18.Month[i] <= 9:\n","        data_c18.Quarter[i] = 3\n","    else:\n","        data_c18.Quarter[i] = 4\n","del data_c18['Month']\n","\n","data_c19['Quarter'] = 0\n","for i in range(len(data_c19)):\n","    if data_c19.Month[i] >= 1 and data_c19.Month[i] <= 3:\n","        data_c19.Quarter[i] = 1\n","    elif data_c19.Month[i] > 3 and data_c19.Month[i] <= 6:\n","        data_c19.Quarter[i] = 2\n","    elif data_c19.Month[i] > 6 and data_c19.Month[i] <= 9:\n","        data_c19.Quarter[i] = 3\n","    else:\n","        data_c19.Quarter[i] = 4\n","del data_c19['Month']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Io_ufPYtZwtI"},"source":["data = data_d.append(data_s.append(data_c17.append(data_c18.append(data_c19))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"id":"9srqUJM2O5W8","executionInfo":{"status":"ok","timestamp":1623187391678,"user_tz":420,"elapsed":263,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"57b251d6-6be5-4774-b230-93c3d32a6050"},"source":["data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Quarter</th>\n","      <th>Year</th>\n","      <th>Prompt</th>\n","      <th>Result</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2017</td>\n","      <td>When it comes to data privacy</td>\n","      <td>it's important to remember that the government...</td>\n","      <td>democrats</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2017</td>\n","      <td>When it comes to data privacy</td>\n","      <td>it's important to understand that the governme...</td>\n","      <td>democrats</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2017</td>\n","      <td>When it comes to data privacy</td>\n","      <td>there are a lot of things that can be done to ...</td>\n","      <td>democrats</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2017</td>\n","      <td>When it comes to data privacy</td>\n","      <td>there are a lot of people who are not happy wi...</td>\n","      <td>democrats</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2017</td>\n","      <td>When it comes to data privacy</td>\n","      <td>it's important to keep in mind that the govern...</td>\n","      <td>democrats</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>535</th>\n","      <td>535</td>\n","      <td>2</td>\n","      <td>2019</td>\n","      <td>When it comes to Facebook, the government should</td>\n","      <td>be able to ban it. \\n\\n The government shouldn...</td>\n","      <td>conservative</td>\n","    </tr>\n","    <tr>\n","      <th>536</th>\n","      <td>536</td>\n","      <td>2</td>\n","      <td>2019</td>\n","      <td>When it comes to Facebook, the government should</td>\n","      <td>not be able to control the content of its user...</td>\n","      <td>conservative</td>\n","    </tr>\n","    <tr>\n","      <th>537</th>\n","      <td>537</td>\n","      <td>2</td>\n","      <td>2019</td>\n","      <td>When it comes to Facebook, the government should</td>\n","      <td>be able to regulate it. \\n\\n The government sh...</td>\n","      <td>conservative</td>\n","    </tr>\n","    <tr>\n","      <th>538</th>\n","      <td>538</td>\n","      <td>2</td>\n","      <td>2019</td>\n","      <td>When it comes to Facebook, the government should</td>\n","      <td>have the power to ban it. \\n\\n The government ...</td>\n","      <td>conservative</td>\n","    </tr>\n","    <tr>\n","      <th>539</th>\n","      <td>539</td>\n","      <td>2</td>\n","      <td>2019</td>\n","      <td>When it comes to Facebook, the government should</td>\n","      <td>be able to control what you post. \\n\\n The gov...</td>\n","      <td>conservative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4500 rows Ã— 6 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0  ...         label\n","0             0  ...     democrats\n","1             1  ...     democrats\n","2             2  ...     democrats\n","3             3  ...     democrats\n","4             4  ...     democrats\n","..          ...  ...           ...\n","535         535  ...  conservative\n","536         536  ...  conservative\n","537         537  ...  conservative\n","538         538  ...  conservative\n","539         539  ...  conservative\n","\n","[4500 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"9ZPKt8rupAPq"},"source":["## D2V 50D with UMAP\n"]},{"cell_type":"code","metadata":{"id":"ndMchvvipwTN"},"source":["import spacy\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.models import Word2Vec\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIkmQqG6pC1-"},"source":["prompts = data['Prompt'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ot7uDtd0tyN2"},"source":["nlp = spacy.load('en')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epwEBmdDt8T2"},"source":["#### Prompt 0"]},{"cell_type":"code","metadata":{"id":"SAApOf9At8T3"},"source":["data_0 = data[data.Prompt == prompts[0]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsuMheSzt8T5"},"source":["texts, article = [], []\n","for text in data_0['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YfeXR_It8T5"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZTFIJFmt8T5"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AadsRa2t8T6"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCuicAgCt8T6"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDQqArz2t8T6"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OGmeHMT2cLiN"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"i3EEaXJ-qPqo"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8xxUE3CynG5"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_EqF4BWt8T7"},"source":["# Add D2V results back into DF\n","data_0_embeddings = data_0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5M9R4hwfeAmC","executionInfo":{"status":"ok","timestamp":1623187503711,"user_tz":420,"elapsed":29,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"fb3567cd-723f-463b-c62f-7275181bd22e"},"source":["data_0_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_0_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lt0VuPkkfl8E"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qnRsQYhDfmGM"},"source":["#### Prompt 1"]},{"cell_type":"code","metadata":{"id":"G0oOQ8XyfmGN"},"source":["data_1 = data[data.Prompt == prompts[1]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljKNpTa_fmGN"},"source":["texts, article = [], []\n","for text in data_1['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CBJRjjzRfmGN"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDjNVGOHfmGN"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4nQ_IxSfmGO"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6k4snnJ5fmGO"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0GQ6uhofmGO"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"acKn0swHfmGO"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"m65Mem6zfmGP"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AmucX3ZfmGP"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mC1tAwmlfmGP"},"source":["# Add D2V results back into DF\n","data_1_embeddings = data_1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxbP4IPHfmGP","executionInfo":{"status":"ok","timestamp":1623187543944,"user_tz":420,"elapsed":26,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"2c24900f-3747-4c71-a61f-33cc256ea83e"},"source":["data_1_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_1_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"m26KKdvNuREQ"},"source":["#### Prompt 2"]},{"cell_type":"code","metadata":{"id":"sP9sEwqNuREQ"},"source":["data_2 = data[data.Prompt == prompts[2]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzUA_uyauREQ"},"source":["texts, article = [], []\n","for text in data_2['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxEucE9BuRER"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1p8mkhlevqN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RN3Rq70Fev0C"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RghShIvev0D"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"157zhD5Jev0D"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4AJGsZcev0D"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"smx9p1lBev0D"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"X5bz04PKev0D"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlM1TXYZev0E"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FN3mftiFev0E"},"source":["# Add D2V results back into DF\n","data_2_embeddings = data_2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFGKPRqiev0E","executionInfo":{"status":"ok","timestamp":1623187584250,"user_tz":420,"elapsed":40,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"303fac8e-60ef-4991-fbb8-7ff1131b360b"},"source":["data_2_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_2_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"L3zRuPAlupNZ"},"source":["#### Prompt 3"]},{"cell_type":"code","metadata":{"id":"ytwd3gYoupNc"},"source":["data_3 = data[data.Prompt == prompts[3]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wk9uglVPupNh"},"source":["texts, article = [], []\n","for text in data_3['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX60w19DupNh"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfJ7_-pLvjOU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHBJXzX-e42j"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsMBBDFce42k"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDMzj50ce42k"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sjTNxAEe42k"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksnpqRR1e42k"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"yYvyZznMe42k"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ht3w-7jve42l"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J3SFZHFJe42l"},"source":["# Add D2V results back into DF\n","data_3_embeddings = data_3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7FG3A1ce42l","executionInfo":{"status":"ok","timestamp":1623187625313,"user_tz":420,"elapsed":28,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"b090b374-2cea-4e40-f82a-674968b64e9c"},"source":["data_3_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_3_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"GDJVWeMOvjxh"},"source":["#### Prompt 4"]},{"cell_type":"code","metadata":{"id":"znLj79AGvjxh"},"source":["data_4 = data[data.Prompt == prompts[4]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEQ4SxdMvjxi"},"source":["texts, article = [], []\n","for text in data_4['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_rzaSQcvjxj"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcYUjOf2v4bZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CH8rmQXOfAQi"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlzXS-2bfAQi"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJccIDpXfAQj"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dkBDPh2EfAQj"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zOs0quVcfAQk"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"U8C2UzkvfAQk"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtv2NTmMfAQl"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0Vf6QdYfAQl"},"source":["# Add D2V results back into DF\n","data_4_embeddings = data_4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvD4uCPyfAQm","executionInfo":{"status":"ok","timestamp":1623187665388,"user_tz":420,"elapsed":34,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"4984253c-0cbd-49bf-fff6-7da0bf483296"},"source":["data_4_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_4_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"R3qpjsL8v4mQ"},"source":["#### Prompt 5"]},{"cell_type":"code","metadata":{"id":"MdfAnwD7v4mR"},"source":["data_5 = data[data.Prompt == prompts[5]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8INLSaNv4mR"},"source":["texts, article = [], []\n","for text in data_5['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DlQ0oJDSv4mR"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quRvVDjDwGW4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfE6SxoQfG3T"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhJ-M-h7fG3U"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rNi_vRDXfG3U"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idiNcm5yfG3U"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nNyEzN-QfG3V"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"aDsdyy85fG3V"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufS2L-XXfG3V"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7H1TNh7fG3V"},"source":["# Add D2V results back into DF\n","data_5_embeddings = data_5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7lJOI18fG3V","executionInfo":{"status":"ok","timestamp":1623187706503,"user_tz":420,"elapsed":31,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"e64644f0-0448-4955-b9e4-e1c502b3e21d"},"source":["data_5_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_5_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6sq_mib5wGmO"},"source":["#### Prompt 6"]},{"cell_type":"code","metadata":{"id":"TTagj58AwGmP"},"source":["data_6 = data[data.Prompt == prompts[6]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CBcW0BR1wGmP"},"source":["texts, article = [], []\n","for text in data_6['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWDv30C5wGmP"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nN79bjicwVWT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVFhtMw4fMsJ"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ou73J51fMsK"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JsXuBnSfMsK"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HZ77OOqfMsK"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"flBNcMNSfMsK"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"2vcqbc1XfMsK"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dz6L-79xfMsL"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjKv3BUnfMsL"},"source":["# Add D2V results back into DF\n","data_6_embeddings = data_6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3MSpkHXfMsL","executionInfo":{"status":"ok","timestamp":1623187746464,"user_tz":420,"elapsed":22,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"1fcf86c8-0cf9-4803-ea0f-c2373fd190ce"},"source":["data_6_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_6_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"bSeh2JgzwV41"},"source":["#### Prompt 7"]},{"cell_type":"code","metadata":{"id":"5h5ooO2JwV41"},"source":["data_7 = data[data.Prompt == prompts[7]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TDW1Y2RwV41"},"source":["texts, article = [], []\n","for text in data_7['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38ZIimy8wV41"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ERkNSDWwwPp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YM1TJv8BfSar"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PU44F2NYfSas"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvPvNm1bfSas"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gaU88hcdfSas"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NcoU5MzUfSas"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"X-seyy2afSas"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnh5Phr1fSas"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gvb6BSxQfSat"},"source":["# Add D2V results back into DF\n","data_7_embeddings = data_7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uaf9DWBQfSat","executionInfo":{"status":"ok","timestamp":1623187786386,"user_tz":420,"elapsed":28,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"228567d3-5d84-4251-96e5-92d48fb472e1"},"source":["data_7_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_7_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"aG8skOzTwwmc"},"source":["#### Prompt 8"]},{"cell_type":"code","metadata":{"id":"YqHmLsq-wwmd"},"source":["data_8 = data[data.Prompt == prompts[8]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQSG8GuVwwmd"},"source":["texts, article = [], []\n","for text in data_8['Result']:\n","    text = text.replace('\\n\\n', '')\n","    doc = nlp(text)\n","    article = []\n","    for w in doc:\n","        # if it's not a stop word or punctuation mark, add it to our article!\n","        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n","            # we add the lematized version of the word\n","            article.append(w.lemma_)\n","\n","    texts.append(article)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6bOnkZvwwme"},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U43YcJC3fZBf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vO66a1_FfZJd"},"source":["d2vmodel = Doc2Vec(documents, vector_size=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zl66wkbTfZJe"},"source":["w2vmodel = Word2Vec(\n","        texts,\n","        size=100,\n","        window=10,\n","        workers=10,\n","        iter=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjxjAUOAfZJe"},"source":["def create_vector(text, model, model_type=None):\n","    if model_type == \"word2vec\":\n","        vectors = []\n","        for word in text:\n","            try:\n","                vectors.append(model.wv[word])\n","            except KeyError:\n","                pass\n","        if len(vectors) > 0:\n","            return np.mean(vectors, axis=0)\n","    if model_type == \"doc2vec\":\n","        vector = model.infer_vector(text)\n","        return vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkYaS8V4fZJf"},"source":["d2v_results = []\n","for text in texts:\n","  d2v = create_vector(text, d2vmodel, model_type=\"doc2vec\")\n","  d2v_results.append(d2v)\n","d2v_results = [l.tolist() for l in d2v_results]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4lT3z3efZJf"},"source":["UMAP for dimension reduction"]},{"cell_type":"code","metadata":{"id":"WN8YOPMlfZJf"},"source":["reducer = umap.UMAP()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAHS3XPIfZJf"},"source":["embedding_umap = reducer.fit_transform(d2v_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojk5J_1xfZJg"},"source":["# Add D2V results back into DF\n","data_8_embeddings = data_8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMwpoOKNfZJg","executionInfo":{"status":"ok","timestamp":1623187826824,"user_tz":420,"elapsed":35,"user":{"displayName":"Pete Cuppernull","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQIHLo2HkOpoxzeqpCYhfYRnMkdkhwXbSFbB83kg=s64","userId":"11926985991372196066"}},"outputId":"54cd853c-f998-44d2-ac4d-27caf7af3260"},"source":["data_8_embeddings['umap_x'] = embedding_umap[:, 0]\n","data_8_embeddings['umap_y'] = embedding_umap[:, 1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"tPn20is5xP3Z"},"source":["## Combine Embedding Data"]},{"cell_type":"code","metadata":{"id":"m3-FuXn5xSR2"},"source":["final_df = data_0_embeddings.append(data_1_embeddings.append(data_2_embeddings.append(data_3_embeddings.append(data_4_embeddings.append(data_5_embeddings.append(data_6_embeddings.append(data_7_embeddings.append(data_8_embeddings))))))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeSrUMkJxzCb"},"source":["final_df.to_csv(\"/content/drive/My Drive/Final Project/Data/Embeddings/embeddings-50d-umap-all-subreddits.csv\")"],"execution_count":null,"outputs":[]}]}